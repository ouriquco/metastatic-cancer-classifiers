{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/admin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/Users/admin/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:4317: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().fillna(\n",
      "<ipython-input-97-787a35a478f9>:195: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_non_numeric[\"breast_cancer_diagnosis_desc\"] = df_non_numeric[\"breast_cancer_diagnosis_desc\"].apply(clean_text)\n",
      "<ipython-input-97-787a35a478f9>:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_numeric.interpolate(method='polynomial', inplace=True, order=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.810):\n",
      "{'C': 10, 'max_iter': 100, 'multi_class': 'auto', 'solver': 'liblinear'}\n",
      "Accuracy: 0.8140975987606507\n",
      "Precision: 0.7899031106578276\n",
      "Recall: 0.9579468150896723\n",
      "F1 Score: 0.8658468418110675\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "import preprocessor as p\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "\n",
    "def svc(df):\n",
    "    df[\"breast_cancer_diagnosis_desc\"] = df[\"breast_cancer_diagnosis_desc\"].apply(clean_text)\n",
    "    df_features = df[\"breast_cancer_diagnosis_desc\"]\n",
    "    df_targets = df[\"DiagPeriodL90D\"]\n",
    " \n",
    "    vectorized_features = CountVectorizer()\n",
    "    df_features = vectorized_features.fit_transform(df_features)\n",
    "    print(df_features.shape)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_features, df_targets, test_size=0.2, random_state=42)\n",
    "    SVM = svm.SVC()\n",
    "    # SVM = svc_random_search(SVM, X_train, y_train)\n",
    "    SVM = svc_grid_search(SVM, X_train, y_train)\n",
    "    y_pred = SVM.predict(X_test)\n",
    "\n",
    "    print_metrics(y_test, y_pred)\n",
    "    save_model('saved_models/svm.sav',SVM)\n",
    "\n",
    "def linear_regression(df):\n",
    "    df_features, df_targets = preprocess_data(df)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_features.values, df_targets.values.ravel(), test_size=0.2, random_state=42)\n",
    "    logistic = LogisticRegression(solver=\"lbfgs\",max_iter=10000, tol=0.1)\n",
    "    logistic_model = logistic_regression_grid_search(logistic, X_train, y_train)\n",
    "    y_pred = logistic_model.predict(X_test)\n",
    "    print_metrics(y_test, y_pred)\n",
    "    save_model('saved_models/logistic_regression.sav',logistic_model)\n",
    "\n",
    "def random_forest_classifier(df):\n",
    "    df_features, df_targets = preprocess_data(df)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_features.values, df_targets.values.ravel(), test_size=0.2, random_state=42)\n",
    "    rnd_clf = RandomForestClassifier(n_estimators=500, criterion=\"gini\",  max_leaf_nodes=16, random_state=42, n_jobs =-1)\n",
    "    # rnd_clf_model = random_forest_classifier_pipe_random_search(rnd_clf, X_train, y_train)\n",
    "    rnd_clf.fit(X_train, y_train)\n",
    "    y_pred=  rnd_clf.predict(X_test)\n",
    "    print_metrics(y_test, y_pred)\n",
    "    save_model('saved_models/random_forest_classifier.sav',rnd_clf)\n",
    "\n",
    "def logistic_regression_grid_search(logistic, X_train, y_train):\n",
    "    '''\n",
    "    Best parameter (CV score=0.810):\n",
    "    {'C': 10, 'max_iter': 100, 'multi_class': 'auto', 'solver': 'liblinear'}\n",
    "    '''\n",
    "    param_grid = {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],  \n",
    "        'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "        'multi_class': ['auto', 'ovr'],\n",
    "        'max_iter': [100, 200, 500, 1000],\n",
    "    }\n",
    "\n",
    "    logistic_model = GridSearchCV(logistic, param_grid, n_jobs=-1)\n",
    "    logistic_model.fit(X_train, y_train)\n",
    "    print(\"Best parameter (CV score=%0.3f):\" % logistic_model.best_score_)\n",
    "    print(logistic_model.best_params_)\n",
    "    return logistic_model\n",
    "\n",
    "def random_forest_classifier_pipe_random_search(rnd_clf, X_train, y_train):\n",
    "    n_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "    max_depth.append(None)\n",
    "    min_samples_split = [2,5,10]\n",
    "    min_samples_leaf = [1,2,4]\n",
    "    bootstrap = [True, False]\n",
    "\n",
    "    random_grid = { 'random_forest__n_estimators': n_estimators,\n",
    "                    'random_forest__max_features': max_features,\n",
    "                    'random_forest__max_depth': max_depth,\n",
    "                    'random_forest__min_samples_split': min_samples_split,\n",
    "                    'random_forest__min_samples_leaf': min_samples_leaf,\n",
    "                    'random_forest__bootstrap': bootstrap}\n",
    "    \n",
    "    pipe = Pipeline(steps=[(\"pca\",PCA()),(\"random_forest\", rnd_clf)])\n",
    "    rnd_clf_model = random_search_cv(pipe, random_grid)\n",
    "    rnd_clf_model.fit(X_train, y_train)\n",
    "    print(\"Best parameter (CV score=%0.3f):\" % rnd_clf_model.best_score_)\n",
    "    print(rnd_clf_model.best_params_)\n",
    "    return rnd_clf_model\n",
    "\n",
    "def svc_random_search(SVM, X_train, y_train):\n",
    "    '''\n",
    "    Best parameter (CV score=0.810):\n",
    "    {'kernel': 'rbf', 'gamma': 0.1, 'C': 10}\n",
    "    '''\n",
    "    param_grid = {'C': [0.1, 1, 10, 100],\n",
    "              'kernel': ['linear', 'rbf', 'poly'],\n",
    "              'gamma': np.logspace(-3, 2, num=6)}\n",
    "    svc_model = random_search_cv(SVM,param_grid)\n",
    "    svc_model.fit(X_train, y_train)\n",
    "    print(\"Best parameter (CV score=%0.3f):\" % svc_model.best_score_)\n",
    "    print(svc_model.best_params_)\n",
    "    return svc_model\n",
    "\n",
    "def svc_grid_search(SVM, X_train, y_train):\n",
    "    '''\n",
    "    Best parameter (CV score=0.810):\n",
    "    {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
    "    '''\n",
    "    param_grid = {'C': [1, 10, 20],\n",
    "              'kernel': ['rbf'],\n",
    "              'gamma': [0.1,.5,1,10]}\n",
    "    \n",
    "    svm_model = GridSearchCV(SVM, param_grid, n_jobs=-1)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    print(\"Best parameter (CV score=%0.3f):\" % svm_model.best_score_)\n",
    "    print(svm_model.best_params_)\n",
    "    return svm_model\n",
    "    \n",
    "\n",
    "def print_metrics(y_test, y_pred):\n",
    "\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    precision = metrics.precision_score(y_test, y_pred)\n",
    "    recall = metrics.recall_score(y_test, y_pred)\n",
    "    f1 = metrics.f1_score(y_test, y_pred)\n",
    "\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1 Score: {f1}')\n",
    "\n",
    "def save_model(file_name, model):\n",
    "    pkl.dump(model, open(file_name, 'wb'))\n",
    "\n",
    "def load_model(file_name):\n",
    "    return pkl.load(open(file_name, 'rb'))\n",
    "\n",
    "def one_hot_encode(df, type):\n",
    "    return pd.get_dummies(df, dtype=type)\n",
    "\n",
    "def random_search_cv(estimator, random_grid):\n",
    "    return RandomizedSearchCV(estimator=estimator, param_distributions = random_grid, n_iter=100, cv=3, verbose=2, random_state=42, n_jobs =-1)\n",
    "\n",
    "def clean_text(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # This effectively removes all special characters without removing other\n",
    "    # characters from different languages\n",
    "    text = p.clean(text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    # remove leading and trailing white spaces with strip()\n",
    "    # remove custom stopwords from text\n",
    "    cleaned_words = []\n",
    "    for word in words:\n",
    "        word = word.strip()\n",
    "\n",
    "        if word in stop_words:\n",
    "            continue\n",
    "        if word == \"malig\":\n",
    "            word = \"malignant\"\n",
    "        elif word == \"neoplm\":\n",
    "            word = \"neoplasm\"\n",
    "        \n",
    "        cleaned_words.append(word)\n",
    "\n",
    "    text = ' '.join(cleaned_words)\n",
    "    # Replace multiple consecutive white spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def perform_pca_on_model(model_name, model):\n",
    "    pca = PCA()\n",
    "    pipe = Pipeline(steps=[(\"pca\", pca), (model_name, model)])\n",
    "    return pipe, \n",
    "\n",
    "def scale_and_combine_df(df_numeric, df_non_numeric):\n",
    "    x = df_numeric.values\n",
    "    x_scaled = StandardScaler().fit_transform(x)\n",
    "    df_numeric_scaled = pd.DataFrame(x_scaled, columns=df_numeric.columns)\n",
    "    df_final = pd.concat([df_numeric_scaled, df_non_numeric], axis=1)\n",
    "    return df_final\n",
    "\n",
    "def preprocess_data(df):   \n",
    "    df.drop(columns=[\"bmi\", \"patient_race\", \"metastatic_first_novel_treatment\", \"metastatic_first_novel_treatment_type\"], inplace=True)\n",
    "    df_targets = pd.DataFrame(df[\"DiagPeriodL90D\"])\n",
    "    df.drop(columns=[\"DiagPeriodL90D\"], inplace=True)\n",
    "    df_non_numeric = df.select_dtypes(exclude=['number'])\n",
    "    df_non_numeric.fillna('CC', inplace=True)\n",
    "    # Clean non numeric column\n",
    "    df_non_numeric[\"breast_cancer_diagnosis_desc\"] = df_non_numeric[\"breast_cancer_diagnosis_desc\"].apply(clean_text)\n",
    "    df_non_numeric = one_hot_encode(df_non_numeric, float)\n",
    "\n",
    "    df_numeric = df.select_dtypes(include=['number'])\n",
    "    # df_numeric.fillna(df_numeric.mean().round(1), inplace=True)\n",
    "    df_numeric.interpolate(method='polynomial', inplace=True, order=2)\n",
    "\n",
    "    df_final = scale_and_combine_df(df_numeric, df_non_numeric)\n",
    "    return df_final, df_targets\n",
    "\n",
    "def load_data():\n",
    "    nltk.download('stopwords')\n",
    "    df = pd.read_csv(\"training_wids2024C1.csv\")\n",
    "    linear_regression(df)\n",
    "    # random_forest_classifier(df)\n",
    "    # svc(df)\n",
    "\n",
    "\n",
    "def main():\n",
    "    load_data()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
